# IndexingTaskManager 并发调用改进测试指南

## 🧪 测试概述

本测试指南提供了完整的验证方案，用于测试 IndexingTaskManager 嵌入模型并发调用改进的功能正确性、性能提升和稳定性。

## 📋 测试环境准备

### 硬件要求
- **CPU**：4核心以上（推荐8核心）
- **内存**：8GB以上（推荐16GB）
- **网络**：稳定的互联网连接

### 软件依赖
- **.NET 8.0** 或更高版本
- **Qdrant 向量数据库**：运行在 localhost:6334
- **嵌入向量提供商**：Ollama（本地）或 DashScope（云端）

### 测试数据
- **小型项目**：50-100个 C# 文件
- **中型项目**：200-500个 C# 文件  
- **大型项目**：1000+ 个 C# 文件

## 🔧 测试配置

### 基准配置（串行处理）
```json
{
  "CodeSearch": {
    "IndexingSettings": {
      "concurrencySettings": {
        "maxConcurrentEmbeddingRequests": 1,
        "maxConcurrentFileBatches": 1,
        "embeddingBatchSizeOptimal": 5,
        "enableConcurrencyLogging": true
      }
    }
  }
}
```

### 并发配置（并发处理）
```json
{
  "CodeSearch": {
    "IndexingSettings": {
      "concurrencySettings": {
        "maxConcurrentEmbeddingRequests": 4,
        "maxConcurrentFileBatches": 2,
        "embeddingBatchSizeOptimal": 10,
        "enableConcurrencyLogging": true
      }
    }
  }
}
```

### 高并发配置（压力测试）
```json
{
  "CodeSearch": {
    "IndexingSettings": {
      "concurrencySettings": {
        "maxConcurrentEmbeddingRequests": 8,
        "maxConcurrentFileBatches": 4,
        "embeddingBatchSizeOptimal": 15,
        "enableConcurrencyLogging": true
      }
    }
  }
}
```

## 🧪 功能测试用例

### 测试用例 1：基本并发功能验证
**目标**：验证并发处理的基本功能正确性

**步骤**：
1. 启动服务，使用并发配置
2. 执行代码库索引：`POST /codebase-index`
3. 监控日志输出，确认并发处理
4. 验证索引结果完整性

**预期结果**：
- 日志显示并发批次处理
- 索引片段数量与串行处理一致
- 无错误或异常发生

### 测试用例 2：并发设置配置验证
**目标**：验证不同并发配置的有效性

**步骤**：
1. 分别使用基准、并发、高并发三种配置
2. 对同一代码库执行索引
3. 记录处理时间和资源使用

**预期结果**：
- 并发度越高，处理时间越短（在合理范围内）
- CPU 利用率随并发度增加
- 内存使用保持在合理范围

### 测试用例 3：错误处理和恢复验证
**目标**：验证并发处理的错误隔离和恢复能力

**步骤**：
1. 在索引过程中模拟网络中断
2. 恢复网络连接
3. 观察系统恢复行为

**预期结果**：
- 部分批次失败不影响其他批次
- 失败批次能够重试恢复
- 整体索引过程能够完成

### 测试用例 4：增量重建并发测试
**目标**：验证增量重建的并发处理能力

**步骤**：
1. 完成初始索引
2. 修改部分代码文件
3. 执行增量重建：`POST /codebase-rebuild`
4. 验证只有变更文件被重新处理

**预期结果**：
- 只处理变更的文件
- 并发处理加速重建过程
- 索引结果正确更新

## ⚡ 性能测试用例

### 性能测试 1：索引速度对比
**目标**：量化并发处理的性能提升

**测试矩阵**：
| 项目规模 | 串行时间 | 并发时间 | 提升比例 | CPU使用率 |
|---------|---------|---------|---------|----------|
| 50文件   | _____s  | _____s  | _____%  | _____%   |
| 200文件  | _____s  | _____s  | _____%  | _____%   |
| 500文件  | _____s  | _____s  | _____%  | _____%   |
| 1000文件 | _____s  | _____s  | _____%  | _____%   |

**测试脚本**：
```bash
# 记录开始时间
start_time=$(date +%s)

# 执行索引
curl -X POST "http://localhost:5000/codebase-index" \
  -H "Content-Type: application/json" \
  -d '{"codebasePath": "/path/to/test/project"}'

# 等待完成并记录结束时间
end_time=$(date +%s)
duration=$((end_time - start_time))
echo "索引完成，耗时: ${duration}秒"
```

### 性能测试 2：内存使用监控
**目标**：验证内存使用优化效果

**监控指标**：
- 峰值内存使用量
- 平均内存使用量
- GC 触发频率
- 内存分配速率

**监控工具**：
```bash
# 使用 dotnet-counters 监控
dotnet-counters monitor --process-id <PID> \
  --counters System.Runtime[gc-heap-size,gc-fragmentation,allocation-rate]
```

### 性能测试 3：网络效率测试
**目标**：验证网络带宽利用率

**测试场景**：
- 本地 Ollama：测量本地网络请求效率
- 云端 DashScope：测量外网带宽利用率

**监控指标**：
- 并发请求数量
- 网络吞吐量
- 请求响应时间
- 请求成功率

## 🔄 稳定性测试用例

### 稳定性测试 1：长时间运行测试
**目标**：验证长时间并发处理的稳定性

**步骤**：
1. 连续处理多个大型代码库（总计6小时以上）
2. 监控内存泄漏和资源占用
3. 记录错误率和恢复情况

**监控指标**：
- 内存使用趋势
- 线程池状态
- 连接池健康状况
- 错误发生频率

### 稳定性测试 2：高并发压力测试
**目标**：验证系统在高并发负载下的表现

**步骤**：
1. 使用最高并发配置
2. 同时处理多个索引任务
3. 监控系统资源和响应性能

**压力指标**：
- 最大并发任务数
- 系统资源利用率
- 响应时间稳定性
- 错误率阈值

### 稳定性测试 3：异常恢复测试
**目标**：验证各种异常情况下的恢复能力

**异常场景**：
- 嵌入向量服务临时不可用
- Qdrant 数据库连接中断
- 磁盘空间不足
- 内存不足

**恢复验证**：
- 异常检测速度
- 自动重试机制
- 状态保持能力
- 完整性保证

## 📊 测试结果记录

### 性能提升记录表
```
测试日期: ___________
测试环境: ___________
测试人员: ___________

基准性能（串行处理）:
- 索引时间: _____秒
- CPU 使用率: _____%
- 内存使用: _____MB
- 错误率: _____%

并发性能（并发处理）:
- 索引时间: _____秒
- CPU 使用率: _____%  
- 内存使用: _____MB
- 错误率: _____%

性能提升:
- 时间节省: _____%
- CPU 利用率提升: _____%
- 内存效率提升: _____%
```

### 功能验证检查表
- [ ] 并发批次正确处理
- [ ] 索引结果完整性验证
- [ ] 进度回调正确更新
- [ ] 错误隔离有效工作
- [ ] 重试机制正常运行
- [ ] 配置参数生效
- [ ] 日志记录完整
- [ ] 资源正确释放

### 问题记录表
| 问题描述 | 严重程度 | 复现步骤 | 解决方案 | 状态 |
|---------|---------|---------|---------|------|
|         |         |         |         |      |

## 🔍 调试和故障排除

### 常见问题排查

**问题 1：并发度设置过高导致性能下降**
- **症状**：CPU 使用率100%，但处理速度变慢
- **原因**：超出硬件承载能力
- **解决**：降低 `maxConcurrentEmbeddingRequests` 参数

**问题 2：内存使用异常增长**
- **症状**：内存使用持续增长，不释放
- **原因**：批次大小过大或资源泄漏
- **解决**：减小 `embeddingBatchSizeOptimal` 参数

**问题 3：网络请求频繁超时**
- **症状**：大量重试日志，处理缓慢
- **原因**：网络不稳定或并发度过高
- **解决**：增加 `networkTimeoutMs` 或降低并发度

### 日志分析要点

**关键日志标识**：
```
[ConcurrentEmbeddingManager] 开始并发处理 N 个文本
[IndexingTaskManager] 并发批处理索引：N 个文件，并发度：X
[EnhancedCodeSemanticSearch] 并发批量索引 N 个代码片段
```

**性能监控日志**：
```
批次 X/Y 并发索引完成：N 个代码片段
文本分为 N 个并发批次
并发嵌入向量处理完成，获得 N 个向量，耗时 X.XX 秒
```

## ✅ 验收标准

### 功能验收
- [ ] 所有并发功能正常工作
- [ ] 索引结果与串行处理完全一致
- [ ] 错误处理和恢复机制有效
- [ ] 配置参数正确生效

### 性能验收
- [ ] 大型项目索引时间减少 ≥ 40%
- [ ] CPU 利用率提升 ≥ 50%
- [ ] 内存使用效率提升 ≥ 30%
- [ ] 错误率 ≤ 1%

### 稳定性验收
- [ ] 6小时连续运行无崩溃
- [ ] 高并发压力测试通过
- [ ] 异常恢复机制验证通过
- [ ] 资源泄漏检查通过

通过以上完整的测试方案，可以全面验证 IndexingTaskManager 嵌入模型并发调用改进的效果，确保功能的正确性、性能的提升和系统的稳定性。